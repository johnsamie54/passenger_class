{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a97151b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f619d93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Definitions</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>Country interviewee is in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>Year survey was done in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid</td>\n",
       "      <td>Unique identifier for each interviewee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_type</td>\n",
       "      <td>Type of location: Rural, Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cellphone_access</td>\n",
       "      <td>If interviewee has access to a cellphone: Yes, No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>household_size</td>\n",
       "      <td>Number of people living in one house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_of_respondent</td>\n",
       "      <td>The age of the interviewee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender_of_respondent</td>\n",
       "      <td>Gender of interviewee: Male, Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relationship_with_head</td>\n",
       "      <td>The interviewee’s relationship with the head o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>The martial status of the interviewee: Married...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education_level</td>\n",
       "      <td>Highest level of education: No formal educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job_type</td>\n",
       "      <td>Type of job interviewee has: Farming and Fishi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable Definitions                                         Unnamed: 1\n",
       "0                  country                         Country interviewee is in.\n",
       "1                     year                           Year survey was done in.\n",
       "2                 uniqueid             Unique identifier for each interviewee\n",
       "3            location_type                     Type of location: Rural, Urban\n",
       "4         cellphone_access  If interviewee has access to a cellphone: Yes, No\n",
       "5           household_size               Number of people living in one house\n",
       "6        age_of_respondent                         The age of the interviewee\n",
       "7     gender_of_respondent                Gender of interviewee: Male, Female\n",
       "8   relationship_with_head  The interviewee’s relationship with the head o...\n",
       "9           marital_status  The martial status of the interviewee: Married...\n",
       "10         education_level  Highest level of education: No formal educatio...\n",
       "11                job_type  Type of job interviewee has: Farming and Fishi..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the datas valuable description\n",
    "pd.read_csv(\"VariableDefinitions (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868389aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>uniqueid</th>\n",
       "      <th>bank_account</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_2</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Government Dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Vocational/Specialised training</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_4</td>\n",
       "      <td>No</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Formally employed Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>uniqueid_5</td>\n",
       "      <td>No</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year    uniqueid bank_account location_type cellphone_access  \\\n",
       "0   Kenya  2018  uniqueid_1          Yes         Rural              Yes   \n",
       "1   Kenya  2018  uniqueid_2           No         Rural               No   \n",
       "2   Kenya  2018  uniqueid_3          Yes         Urban              Yes   \n",
       "3   Kenya  2018  uniqueid_4           No         Rural              Yes   \n",
       "4   Kenya  2018  uniqueid_5           No         Urban               No   \n",
       "\n",
       "   household_size  age_of_respondent gender_of_respondent  \\\n",
       "0               3                 24               Female   \n",
       "1               5                 70               Female   \n",
       "2               5                 26                 Male   \n",
       "3               5                 34               Female   \n",
       "4               8                 26                 Male   \n",
       "\n",
       "  relationship_with_head           marital_status  \\\n",
       "0                 Spouse  Married/Living together   \n",
       "1      Head of Household                  Widowed   \n",
       "2         Other relative     Single/Never Married   \n",
       "3      Head of Household  Married/Living together   \n",
       "4                  Child     Single/Never Married   \n",
       "\n",
       "                   education_level                   job_type  \n",
       "0              Secondary education              Self employed  \n",
       "1              No formal education       Government Dependent  \n",
       "2  Vocational/Specialised training              Self employed  \n",
       "3                Primary education  Formally employed Private  \n",
       "4                Primary education        Informally employed  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examinining the train dataset\n",
    "df_train=pd.read_csv(\"train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e0b00e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor)])\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Fit the pipeline to the training data\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Transform the training data\u001b[39;00m\n\u001b[0;32m     36\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mtransform(df_train)\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:657\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m    This estimator.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:690\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 690\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_transform_one\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:621\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    615\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    617\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    618\u001b[0m     )\n\u001b[0;32m    619\u001b[0m )\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\datasciencez\\lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"marital_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d091bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examining the test dataset\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1910b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the  shape of train  and test datsets\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission files\n",
    "submission=pd.read_csv(\"SampleSubmission.csv\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758485a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descriptive discription about the  test dataset of numeric values of test_data\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056feb1a",
   "metadata": {},
   "source": [
    "hhalf of the people have 35yrs and below while 75% and below  have 49 yrs and below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking about the categprical distribution\n",
    "df_train.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking whether the dataset is balanced\n",
    "df_train[\"bank_account\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889e03a",
   "metadata": {},
   "source": [
    "imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f46f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting to know about datasets\n",
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking some visiualization for normal disribution \n",
    "df_train.hist(bins=25,figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491be7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkinmg for normal distibution by use of kurtosis\n",
    "df_train.kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd506c",
   "metadata": {},
   "source": [
    "the data  features shows  slightly  normal distibution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by use of boxplots\n",
    "sns.boxplot(data=df_train, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3044d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_train,orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac82c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select_dtypes(include=\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec09e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing somme libraries for preeprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oh=OneHotEncoder()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6a8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28243990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the train data to depedent and indepedent variables\n",
    "#transforming the target variable\n",
    "df_train[\"bank_account\"]=le.fit_transform(df_train[\"bank_account\"])\n",
    "y_train=df_train[\"bank_account\"]\n",
    "x_train=df_train.drop(\"bank_account\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocsessing_data(df_train):\n",
    "    # categorical features to be onverted to One Hot Encoding\n",
    "    ohe_df=pd.DataFrame(df_train, columns=[\"relationship_with_head\",\"country\",\"location_type\"])\n",
    "    # generate binary values using get_dummies\n",
    "    dum_df = pd.get_dummies(ohe_df, columns=[\"relationship_with_head\",\"country\",\"location_type\"], prefix=[\"Type_is\",\"Type_is\",\"Type_is\"])\n",
    "    # merge with main df bridge_df on key values\n",
    "    df_train=df_train.join(dum_df)\n",
    "    \n",
    "    # Label Encoder conversion\n",
    "    df_train[\"cellphone_access\"] = le.fit_transform(df_train[\"cellphone_access\"])\n",
    "    df_train[\"gender_of_respondent\"] = le.fit_transform(df_train[\"gender_of_respondent\"])\n",
    "    df_train[\"year\"] = le.fit_transform(df_train[\"year\"])\n",
    "    df_train[\"marital_status\"] = le.fit_transform(df_train[\"marital_status\"])\n",
    "    df_train[\"education_level\"] = le.fit_transform(df_train[\"education_level\"])\n",
    "    df_train[\"job_type\"] = le.fit_transform(df_train[\"job_type\"])\n",
    "\n",
    "    \n",
    "    # drop uniquid column\n",
    "    df_train=df_train.drop(columns=[\"uniqueid\",\"relationship_with_head\",\"country\",\"location_type\"],axis=1)\n",
    "    \n",
    "    # scale our data into range of 0 and 1\n",
    "    scaler=StandardScaler() \n",
    "    df_train=scaler.fit_transform(df_train)\n",
    "    \n",
    "    return df_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "procesed_train=preprocsessing_data(df_train)\n",
    "processd_test=preprocsessing_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(procesed_train.shape)\n",
    "print(processd_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spltting train data to test and validation dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_Train,x_valid,y_Train,y_valid=train_test_split(procesed_train,y_train,test_size=0.1,\n",
    "                                                 stratify = y_train,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model building\n",
    "#importing models from various libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier    \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9cf560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builiding pippeline for the models\n",
    "pipe_dt=Pipeline([(\"decision tree\",DecisionTreeClassifier())])\n",
    "\n",
    "pipe_rf=Pipeline([(\"random forest\",RandomForestClassifier())])\n",
    "\n",
    "pipe_svc=Pipeline([(\"svc\",SVC())])\n",
    "\n",
    "pipe_knearest=Pipeline([(\"kneigbour\",KNeighborsClassifier())])\n",
    "\n",
    "pipe_naibayes=Pipeline([(\"gaussian nb\",GaussianNB())])\n",
    "\n",
    "pipe_adboost=Pipeline([(\"adboost\",AdaBoostClassifier())])\n",
    "\n",
    "pipe_gradientboost=Pipeline([(\"gradient\",GradientBoostingClassifier())])\n",
    "\n",
    "pipe_extratree=Pipeline([(\"etra_tree\",ExtraTreesClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c333e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming a list for the modelels\n",
    "pipe_models=[pipe_dt,pipe_rf,pipe_svc,pipe_knearest,pipe_naibayes,pipe_adboost,pipe_gradientboost,pipe_extratree]\n",
    "pipe_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_dict={0:\"DecisionTreeClassifier\",\n",
    "         1:\"RandomForestClassifier\",\n",
    "         2:\"SVC\",\n",
    "         3:\"KNeighborsClassifier\",\n",
    "         4:\"GaussianNB\",\n",
    "         5:\"AdaBoostClassifier\",\n",
    "         6:\"GradientBoostingClassifier\",\n",
    "         7:\"ExtraTreesClassifier\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b58638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#training the models\n",
    "for model in pipe_models:\n",
    "    model.fit(x_Train,y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the scores of the models\n",
    "for i,model in enumerate(pipe_models):\n",
    "    print(\"{} valid score is {}\".format(pipe_dict[i],model.score(x_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff675b9",
   "metadata": {},
   "source": [
    "AdaBoostClassifier valid score and the GradientBoostingClassifier valid score  classifier gives the highest score and therefore we are going to hypertune them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using grid search\n",
    "adbost=AdaBoostClassifier()\n",
    "param_grid={\"n_estimators\":[50,100,200,250,300,400,450,500],\n",
    "            \"learning_rate\":[1.0,0.1,0.01]}\n",
    "ad_bostgrid= GridSearchCV(adbost,param_grid,cv=5,n_jobs=1)\n",
    "\n",
    "ad_bostgrid.fit(x_Train,y_Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=ad_bostgrid.predict(x_valid)\n",
    "print(confusion_matrix(y_valid,y_predict))\n",
    "print(\"accuracy_score is\",accuracy_score(y_valid,y_predict))\n",
    "print(\"error is\",1-accuracy_score(y_valid,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient=GradientBoostingClassifier(n_estimators=200,max_depth=4,min_samples_split=2,learning_rate=0.1, min_samples_leaf=2)\n",
    "gradient.fit(x_Train,y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=gradient.predict(x_valid)\n",
    "print(confusion_matrix(y_valid,y_predict))\n",
    "print(\"accuracy_score is\",accuracy_score(y_valid,y_predict))\n",
    "print(\"error is\",1-accuracy_score(y_valid,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698bd9f",
   "metadata": {},
   "source": [
    "after hypertuning the model accuracy increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24574bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=gradient.predict(processd_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38622ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission file\n",
    "submission={\"unique_id\":df_test[\"uniqueid\"],\"bank_account\":prediction}\n",
    "submission_df=pd.DataFrame(submission)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39990158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create submission csv file csv file\n",
    "submission_df.to_csv('first_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5585f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
